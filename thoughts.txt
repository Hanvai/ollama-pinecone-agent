Ollama: Runs Llama2 locally for LLM capabilities (embeddings, chat).
Pinecone: Cloud vector database for storing and searching embeddings.
Spring Boot: Backend framework for API and service orchestration.
REST API: Exposes endpoints for interaction.


Typical Use Cases
Personal AI assistant that remembers past interactions and uses them for better responses.
Semantic search over a knowledge base or document set.
Conversational agent that can learn and recall information over time.

In summary:
Application is a local AI agent that can understand, remember, and reason about tasks and information using Llama2 and Pinecone, accessible via a REST API.
